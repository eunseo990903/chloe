{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9b7cca-61a0-460b-bc83-19892b9b4bb1",
   "metadata": {},
   "source": [
    "## 한글 NLP \n",
    "* 네이버 영화 평점 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a87552-1790-4050-aee9-96b24a037ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25173\n",
       "0    24827\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import konlpy\n",
    "import pandas as pd\n",
    "\n",
    "train_df=pd.read_csv('ratings_train.txt', sep='\\t', encoding ='utf-8')\n",
    "train_df[:10]\n",
    "test_df=pd.read_csv('ratings_test.txt', sep='\\t', encoding ='utf-8')\n",
    "train_df['label'].value_counts() #0부정 1긍정\n",
    "test_df['label'].value_counts() #0부정 1긍정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc03309-df40-496b-8fd2-0650d298ff0d",
   "metadata": {},
   "source": [
    "### 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17dca597-611a-4319-b4e0-03818c83da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# na를 공백으로\n",
    "train_df=train_df.fillna('')\n",
    "test_df=test_df.fillna('')\n",
    "\n",
    "#정규표현식 : 숫자를 공백으로 변경\n",
    "train_df['document']=train_df['document'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "test_df['document']=test_df['document'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "#id 칼럼 삭제\n",
    "train_df.drop('id', axis=1, inplace=True)\n",
    "test_df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f60d5038-e972-4343-805d-2dbe46e581ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10%만 랜덤하게 뽑기\n",
    "train_df=train_df.sample(frac=0.1)\n",
    "test_df=test_df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca1c85-21ba-43eb-8a99-505fb02f2c4c",
   "metadata": {},
   "source": [
    "* 형태소 단어로 토큰화\n",
    "* morphs() 메서도 이용-토큰화해 객체 리스트로 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ea4c58f-36f1-4a58-a739-7a1bed8ab1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt= Okt()\n",
    "def tw_tokenizer(text):\n",
    "    tokens_ko=twitter.morphs(text)\n",
    "    return tokens_ko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8043a23-e96c-44a0-b330-421647b3a4bb",
   "metadata": {},
   "source": [
    "## 피처 벡터화  TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b4b5b88-2e63-4d3e-b139-9d332912bf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tfidf_vect= TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1,2), min_df=3,\n",
    "                           max_df=0.9)\n",
    "tfidf_vect.fit(train_df['document'])\n",
    "tfidf_matrix_train=tfidf_vect.transform(train_df['document'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12235a5-31aa-460f-a43c-77b6dc5f7185",
   "metadata": {},
   "source": [
    "* 로지스틱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4682640a-507d-491c-9431-bebdde7e9c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "{'C': 3.5} 0.8099\n"
     ]
    }
   ],
   "source": [
    "lg_clf= LogisticRegression(random_state=0, solver='liblinear')\n",
    "\n",
    "#파라미터 c최적화를 위해 gridsearch cv 이용\n",
    "params={'C':[1,3.5,4.5,5.5,10]}\n",
    "grid_cv=GridSearchCV(lg_clf,param_grid=params, cv=3, scoring='accuracy',\n",
    "                    verbose=1)\n",
    "grid_cv.fit(tfidf_matrix_train, train_df['label'])\n",
    "print(grid_cv.best_params_, round(grid_cv.best_score_, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b794e81b-46f3-49ea-ba2e-3f59200ca5ef",
   "metadata": {},
   "source": [
    "* testdf 이용해 최종 감성 분석 예측\n",
    "* 테스트 세트 이용해 예측할경우 학습할때 적용한 Tfidvectirozer 그대로 사용\n",
    "* 학습시 설정된 TfidVectorizer의 피처개수와 테스트데이터로 변환할 개수가 같아짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "142d2538-0162-418b-8e48-0cda6d9b0a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 0.8214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#학습 데이터를 적용한 tfid이용해 test df를 TFIDF 값으로 피처 변환\n",
    "tfidf_matrix_test=tfidf_vect.transform(test_df['document'])\n",
    "#gridsearch에서 최적파라미터로 학습된 classifier 그대로 이용 \n",
    "best_estimator=grid_cv.best_estimator_\n",
    "preds= best_estimator.predict(tfidf_matrix_test)\n",
    "\n",
    "print('Logistic Regression accuracy:', accuracy_score(test_df['label'],preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d106000e-31de-48c0-b8ad-7e06fd6662c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
