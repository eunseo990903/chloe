{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdcce1cb-532c-40bc-a751-73d52dae48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e436a38-5c0a-4bc0-a1c9-215fdf888e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 12.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: future in c:\\users\\user\\anaconda3\\lib\\site-packages (from hyperopt) (0.18.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from hyperopt) (1.23.5)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\user\\anaconda3\\lib\\site-packages (from hyperopt) (2.0.0)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "     ------------------------------------- 200.5/200.5 kB 12.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from hyperopt) (2.8.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from hyperopt) (1.10.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from hyperopt) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n",
      "Installing collected packages: py4j, hyperopt\n",
      "Successfully installed hyperopt-0.2.7 py4j-0.10.9.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8136bba2-aafa-4359-9b07-801e3f1a2808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 557.31trial/s, best loss: -519.0]\n",
      "best {'x': 19, 'y': -25.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "space_search={'x': hp.randint('x',20), 'y':hp.quniform('y',-50,50,5)} \n",
    "from hyperopt import STATUS_OK\n",
    "def objective_func(search_space):\n",
    "    x=search_space['x']\n",
    "    y=search_space['y']\n",
    "    retval= x*y-x+y\n",
    "    return retval\n",
    "\n",
    "from hyperopt import fmin,tpe, Trials\n",
    "trial_val=Trials() #입력결괏값 저장\n",
    "#20회\n",
    "best=fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=20, \n",
    "         trials=trial_val,rstate=np.random.default_rng(seed=0))\n",
    "print('best', best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40c4f9c9-c304-4a1c-b5fc-f2f47cb27d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#이상치  iqr 기준으로 판별 \n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "x = df['Amount'].values\n",
    "np.percentile(x,25)\n",
    "np.percentile(x,75)-np.percentile(x,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ceec829-28f1-4790-b38f-73a5c133f12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-101.7475 184.5125\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284801</th>\n",
       "      <td>172785.0</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.931005</td>\n",
       "      <td>-0.546012</td>\n",
       "      <td>-0.745097</td>\n",
       "      <td>1.130314</td>\n",
       "      <td>-0.235973</td>\n",
       "      <td>0.812722</td>\n",
       "      <td>0.115093</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314205</td>\n",
       "      <td>-0.808520</td>\n",
       "      <td>0.050343</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>-0.435870</td>\n",
       "      <td>0.124079</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.068803</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252903 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "5            2.0  -0.425966   0.960523  1.141109 -0.168252  0.420987   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284801  172785.0   0.120316   0.931005 -0.546012 -0.745097  1.130314   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "5      -0.029728  0.476201  0.260314 -0.568671  ... -0.208254 -0.559825   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284801 -0.235973  0.812722  0.115093 -0.204064  ... -0.314205 -0.808520   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "5      -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080    3.67   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284801  0.050343  0.102800 -0.435870  0.124079  0.217940  0.068803    2.69   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  \n",
       "...       ...  \n",
       "284801      0  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "\n",
       "[252903 rows x 31 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['Amount']의 하위 이상치 , 상위 이상치 개수는? \n",
    "import pandas as pd\n",
    "df=pd.read_csv('./archive/creditcard.csv')\n",
    "x = df['Amount']\n",
    "iqr=np.percentile(x,75)-np.percentile(x,25)\n",
    "lowest=np.percentile(x,25)-iqr*1.5\n",
    "highest=np.percentile(x,75)+iqr*1.5\n",
    "print(lowest,highest)\n",
    "\n",
    "print(sum(lowest>x))\n",
    "sum(highest<x)\n",
    "\n",
    "#이상치가 아닌 관측치 모으기\n",
    "df_normal=df[df['Amount']<np.percentile(x,75)+1.5*iqr]\n",
    "df_norm\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55d73ecd-3ec2-4865-813f-12a500b5e10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_model_train_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n\u001b[0;32m     17\u001b[0m lgbm_clf \u001b[38;5;241m=\u001b[39m LGBMClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, num_leaves\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, boost_from_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mget_model_train_eval\u001b[49m(lgbm_clf, X_train,X_test, y_train, y_test)) \n\u001b[0;32m     20\u001b[0m get_model_train_eval((lgbm_clf, X_train,X_test,y_train,y_test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_model_train_eval' is not defined"
     ]
    }
   ],
   "source": [
    "#로그 스케일링\n",
    "amount = np.log1p(df_norm)\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1] #class\n",
    "#데이터셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.3)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "lr_pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "print(get_model_train_eval(lgbm_clf, X_train,X_test, y_train, y_test)) \n",
    "\n",
    "get_model_train_eval((lgbm_clf, X_train,X_test,y_train,y_test))\n",
    "# logisticRegression, LightGBM 으로 평가지표 구하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78019319-1304-4fac-8a17-03d66726f279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-98.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(x,25)-(iqr*1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30a1fd83-7fa2-441b-b182-fc491ca5b9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13416\\625210491.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_normal['Amount'] = np.log1p(df_normal['Amount'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[75739    12]\n",
      " [   48    72]]\n",
      "정확도: 0.9992, 정밀도: 0.8571, 재현율: 0.6000,    F1: 0.7059, AUC:0.9441\n",
      "오차 행렬\n",
      "[[75746     5]\n",
      " [   22    98]]\n",
      "정확도: 0.9996, 정밀도: 0.9515, 재현율: 0.8167,    F1: 0.8789, AUC:0.9924\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))  #위치정하는 것 {2: }-> 두번째\n",
    "    \n",
    "\n",
    "get_model_train_eval((lgbm_clf, X_train,X_test,y_train,y_test))\n",
    "y = df_normal.iloc[:, -1]\n",
    "X = df_normal.iloc[:, : -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "def get_model_train_eval(model, ftr_train=None, ftr_test=None, tgt_train=None, tgt_test=None):\n",
    "    model.fit(ftr_train, tgt_train)\n",
    "    pred = model.predict(ftr_test)\n",
    "    pred_proba = model.predict_proba(ftr_test)[:, 1]\n",
    "    get_clf_eval(tgt_test, pred, pred_proba)\n",
    "\n",
    "\n",
    "# LogisticRegression\n",
    "lr_clf = LogisticRegression(max_iter = 1000)\n",
    "get_model_train_eval(lr_clf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm_clf = LGBMClassifier(n_estimators = 1000, num_leaves = 64, n_jobs = -1, boost_from_average = False)\n",
    "get_model_train_eval(lgbm_clf, X_train, X_test, y_train, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f725bf5-7153-4b5c-b7a5-eadecf8e9d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88961</th>\n",
       "      <td>62364.0</td>\n",
       "      <td>1.293053</td>\n",
       "      <td>-0.403680</td>\n",
       "      <td>-0.025024</td>\n",
       "      <td>-0.573741</td>\n",
       "      <td>-0.683430</td>\n",
       "      <td>-0.808288</td>\n",
       "      <td>-0.419516</td>\n",
       "      <td>-0.249010</td>\n",
       "      <td>-0.918470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072886</td>\n",
       "      <td>0.051178</td>\n",
       "      <td>-0.140856</td>\n",
       "      <td>-0.158646</td>\n",
       "      <td>0.453561</td>\n",
       "      <td>-0.263492</td>\n",
       "      <td>0.024845</td>\n",
       "      <td>0.055731</td>\n",
       "      <td>79.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19674</th>\n",
       "      <td>30460.0</td>\n",
       "      <td>-6.283360</td>\n",
       "      <td>-6.338734</td>\n",
       "      <td>0.698809</td>\n",
       "      <td>0.580937</td>\n",
       "      <td>4.603471</td>\n",
       "      <td>-3.033090</td>\n",
       "      <td>-0.220112</td>\n",
       "      <td>-0.608687</td>\n",
       "      <td>0.320713</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.860251</td>\n",
       "      <td>0.843488</td>\n",
       "      <td>4.090418</td>\n",
       "      <td>0.091522</td>\n",
       "      <td>0.904826</td>\n",
       "      <td>1.008558</td>\n",
       "      <td>0.766440</td>\n",
       "      <td>-0.600905</td>\n",
       "      <td>37.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184742</th>\n",
       "      <td>126368.0</td>\n",
       "      <td>2.052188</td>\n",
       "      <td>-0.099089</td>\n",
       "      <td>-1.641736</td>\n",
       "      <td>0.021045</td>\n",
       "      <td>0.375985</td>\n",
       "      <td>-0.826269</td>\n",
       "      <td>0.359470</td>\n",
       "      <td>-0.320135</td>\n",
       "      <td>0.606366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134073</td>\n",
       "      <td>-0.266100</td>\n",
       "      <td>0.193274</td>\n",
       "      <td>0.624724</td>\n",
       "      <td>0.055861</td>\n",
       "      <td>-0.104926</td>\n",
       "      <td>-0.053733</td>\n",
       "      <td>-0.053242</td>\n",
       "      <td>24.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113042</th>\n",
       "      <td>72905.0</td>\n",
       "      <td>-0.343369</td>\n",
       "      <td>1.092825</td>\n",
       "      <td>1.278107</td>\n",
       "      <td>0.066744</td>\n",
       "      <td>-0.024180</td>\n",
       "      <td>-0.985415</td>\n",
       "      <td>0.692278</td>\n",
       "      <td>-0.046993</td>\n",
       "      <td>-0.323509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268206</td>\n",
       "      <td>-0.729425</td>\n",
       "      <td>-0.003556</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>-0.175157</td>\n",
       "      <td>0.073711</td>\n",
       "      <td>0.241619</td>\n",
       "      <td>0.097346</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65283</th>\n",
       "      <td>51511.0</td>\n",
       "      <td>1.103293</td>\n",
       "      <td>-1.167884</td>\n",
       "      <td>1.228438</td>\n",
       "      <td>-0.443103</td>\n",
       "      <td>-1.975890</td>\n",
       "      <td>-0.456641</td>\n",
       "      <td>-1.135544</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>-0.185547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096407</td>\n",
       "      <td>-0.037515</td>\n",
       "      <td>-0.025012</td>\n",
       "      <td>0.418539</td>\n",
       "      <td>-0.090510</td>\n",
       "      <td>1.103867</td>\n",
       "      <td>-0.025231</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>125.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129103</th>\n",
       "      <td>78953.0</td>\n",
       "      <td>1.238010</td>\n",
       "      <td>-0.015896</td>\n",
       "      <td>0.465620</td>\n",
       "      <td>0.203894</td>\n",
       "      <td>-0.800034</td>\n",
       "      <td>-1.272657</td>\n",
       "      <td>-0.029755</td>\n",
       "      <td>-0.246562</td>\n",
       "      <td>0.227769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091096</td>\n",
       "      <td>0.268588</td>\n",
       "      <td>-0.042801</td>\n",
       "      <td>0.808053</td>\n",
       "      <td>0.349425</td>\n",
       "      <td>1.093073</td>\n",
       "      <td>-0.085061</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>19.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69220</th>\n",
       "      <td>53322.0</td>\n",
       "      <td>1.084469</td>\n",
       "      <td>-1.196005</td>\n",
       "      <td>1.075707</td>\n",
       "      <td>-0.499356</td>\n",
       "      <td>-1.291510</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>-1.321282</td>\n",
       "      <td>0.485492</td>\n",
       "      <td>-0.068708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144096</td>\n",
       "      <td>0.455219</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>-0.267182</td>\n",
       "      <td>0.165275</td>\n",
       "      <td>-0.207570</td>\n",
       "      <td>0.068021</td>\n",
       "      <td>0.018580</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228557</th>\n",
       "      <td>145564.0</td>\n",
       "      <td>-0.380354</td>\n",
       "      <td>0.031329</td>\n",
       "      <td>-1.372863</td>\n",
       "      <td>-2.866205</td>\n",
       "      <td>1.672294</td>\n",
       "      <td>3.538435</td>\n",
       "      <td>-0.927608</td>\n",
       "      <td>1.349284</td>\n",
       "      <td>-0.772471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289786</td>\n",
       "      <td>0.667890</td>\n",
       "      <td>0.074755</td>\n",
       "      <td>0.716947</td>\n",
       "      <td>-0.217430</td>\n",
       "      <td>-0.214435</td>\n",
       "      <td>-0.071817</td>\n",
       "      <td>-0.029008</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90491</th>\n",
       "      <td>63042.0</td>\n",
       "      <td>1.322012</td>\n",
       "      <td>-0.297193</td>\n",
       "      <td>0.723172</td>\n",
       "      <td>0.451418</td>\n",
       "      <td>-1.121499</td>\n",
       "      <td>-0.734205</td>\n",
       "      <td>-0.548917</td>\n",
       "      <td>-0.080977</td>\n",
       "      <td>-0.716871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.448655</td>\n",
       "      <td>-0.851629</td>\n",
       "      <td>0.122260</td>\n",
       "      <td>0.301225</td>\n",
       "      <td>0.276891</td>\n",
       "      <td>-0.490392</td>\n",
       "      <td>0.055024</td>\n",
       "      <td>0.034775</td>\n",
       "      <td>7.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138892</th>\n",
       "      <td>82902.0</td>\n",
       "      <td>-0.767093</td>\n",
       "      <td>1.556141</td>\n",
       "      <td>0.651902</td>\n",
       "      <td>0.739097</td>\n",
       "      <td>0.222654</td>\n",
       "      <td>-0.524000</td>\n",
       "      <td>0.513444</td>\n",
       "      <td>0.213977</td>\n",
       "      <td>-0.837474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144358</td>\n",
       "      <td>0.515405</td>\n",
       "      <td>-0.139081</td>\n",
       "      <td>-0.097456</td>\n",
       "      <td>-0.044141</td>\n",
       "      <td>-0.297245</td>\n",
       "      <td>0.175602</td>\n",
       "      <td>0.151791</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28481 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "88961    62364.0  1.293053 -0.403680 -0.025024 -0.573741 -0.683430 -0.808288   \n",
       "19674    30460.0 -6.283360 -6.338734  0.698809  0.580937  4.603471 -3.033090   \n",
       "184742  126368.0  2.052188 -0.099089 -1.641736  0.021045  0.375985 -0.826269   \n",
       "113042   72905.0 -0.343369  1.092825  1.278107  0.066744 -0.024180 -0.985415   \n",
       "65283    51511.0  1.103293 -1.167884  1.228438 -0.443103 -1.975890 -0.456641   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "129103   78953.0  1.238010 -0.015896  0.465620  0.203894 -0.800034 -1.272657   \n",
       "69220    53322.0  1.084469 -1.196005  1.075707 -0.499356 -1.291510  0.937238   \n",
       "228557  145564.0 -0.380354  0.031329 -1.372863 -2.866205  1.672294  3.538435   \n",
       "90491    63042.0  1.322012 -0.297193  0.723172  0.451418 -1.121499 -0.734205   \n",
       "138892   82902.0 -0.767093  1.556141  0.651902  0.739097  0.222654 -0.524000   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "88961  -0.419516 -0.249010 -0.918470  ...  0.072886  0.051178 -0.140856   \n",
       "19674  -0.220112 -0.608687  0.320713  ... -0.860251  0.843488  4.090418   \n",
       "184742  0.359470 -0.320135  0.606366  ... -0.134073 -0.266100  0.193274   \n",
       "113042  0.692278 -0.046993 -0.323509  ... -0.268206 -0.729425 -0.003556   \n",
       "65283  -1.135544  0.021429 -0.185547  ... -0.096407 -0.037515 -0.025012   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "129103 -0.029755 -0.246562  0.227769  ...  0.091096  0.268588 -0.042801   \n",
       "69220  -1.321282  0.485492 -0.068708  ...  0.144096  0.455219  0.002710   \n",
       "228557 -0.927608  1.349284 -0.772471  ...  0.289786  0.667890  0.074755   \n",
       "90491  -0.548917 -0.080977 -0.716871  ... -0.448655 -0.851629  0.122260   \n",
       "138892  0.513444  0.213977 -0.837474  ...  0.144358  0.515405 -0.139081   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "88961  -0.158646  0.453561 -0.263492  0.024845  0.055731   79.90      0  \n",
       "19674   0.091522  0.904826  1.008558  0.766440 -0.600905   37.90      0  \n",
       "184742  0.624724  0.055861 -0.104926 -0.053733 -0.053242   24.05      0  \n",
       "113042  0.315217 -0.175157  0.073711  0.241619  0.097346    6.15      0  \n",
       "65283   0.418539 -0.090510  1.103867 -0.025231  0.047278  125.90      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "129103  0.808053  0.349425  1.093073 -0.085061  0.007053   19.90      0  \n",
       "69220  -0.267182  0.165275 -0.207570  0.068021  0.018580   75.00      0  \n",
       "228557  0.716947 -0.217430 -0.214435 -0.071817 -0.029008   20.00      0  \n",
       "90491   0.301225  0.276891 -0.490392  0.055024  0.034775    7.05      0  \n",
       "138892 -0.097456 -0.044141 -0.297245  0.175602  0.151791    2.65      0  \n",
       "\n",
       "[28481 rows x 31 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71052c98-849a-4fb7-996b-d3a8ea0d2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal.drop(df_normal[df_normal['Class']== 0].sample(frac=0.99).index) \n",
    "# X 의 1%만 뽑아서 X라고 합시다\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "df.drop('Time', axis =1, inplace = True)\n",
    "\n",
    "\n",
    "df_normal = df[df['Amount'] < np.percentile(x, 75 ) + 1.5*iqr]\n",
    "df_normal = df_normal.drop(df_normal[df_normal['Class']== 0].sample(frac=0.99).index)\n",
    "\n",
    "X = df_normal.iloc[:, : -1]\n",
    "y = df_normal.iloc[:, -1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b09827-6fd3-478d-8d21-fa681ae67ea5",
   "metadata": {},
   "source": [
    "## Stacking 스태킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "49ccddb4-de96-4429-8a76-9341ef367dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도: 0.9211\n",
      "랜덤 포레스트 정확도: 0.9649\n",
      "결정 트리 정확도: 0.9123\n",
      "에이다부스트 정확도: 0.9561\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X_data , y_label , test_size=0.2 , random_state=0)\n",
    "\n",
    "# 개별 ML 모델을 위한 Classifier 생성.\n",
    "knn_clf  = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "# 개별 모델들을 학습. \n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "dt_clf.fit(X_train , y_train)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# 학습된 개별 모델들이 각자 반환하는 예측 데이터 셋을 생성하고 개별 모델의 정확도 측정. \n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "ada_pred = ada_clf.predict(X_test)\n",
    "\n",
    "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_test, knn_pred)))\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "print('결정 트리 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "print('에이다부스트 정확도: {0:.4f}'.format(accuracy_score(y_test, ada_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d860ef48-0973-4f0f-be1e-7faa39e50948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n",
      "(114, 4)\n",
      "최종 메타 모델의 예측 정확도: 0.9737\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(pred.shape) # 가로로 되있는걸 transpose해서 세로로 쭉 세워서 그것을 학습데이터로 만든것 \n",
    "# transpose를 이용해 행과 열의 위치 교환. 컬럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦. \n",
    "pred = np.transpose(pred) \n",
    "print (pred.shape)\n",
    "\n",
    "\n",
    "#logistic 회귀 학습 \n",
    "# 최종 Stacking 모델을 위한 Classifier생성. \n",
    "lr_final = LogisticRegression(C=10)\n",
    "lr_final.fit(pred, y_test)  #test 로 fit 해서 과적합 발생할 수 있음 -> cv 세트 기반 스태킹 \n",
    "final = lr_final.predict(pred)\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test , final)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "62a48c32-ec3b-47f7-92e9-c83c7fe8e336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final = LogisticRegression(C=10)\n",
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "pred[:,:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a69c051-9f42-45d5-b7d0-c3ea444fd6b3",
   "metadata": {},
   "source": [
    "97.37 성능향상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d35a07-29b4-4cb7-b498-cbc22eb2987f",
   "metadata": {},
   "source": [
    "## 과적합 개선을 위한 CV 세트 기반 스태킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9462ccba-dec2-4d62-b05f-7995c3d1038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds ):\n",
    "    # 지정된 n_folds값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "\n",
    "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
    "        X_tr = X_train_n[train_index] \n",
    "        y_tr = y_train_n[train_index] \n",
    "        X_te = X_train_n[valid_index]  \n",
    "\n",
    "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_tr , y_tr)       \n",
    "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "   \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "\n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred , test_pred_mean"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cadfce57-7544-4446-9c2f-bb8f671950e4",
   "metadata": {},
   "source": [
    "get_stacking_base_datasets() 함수 생성: 개별 모델의 Classifier 객체, 원본인 학습용 피처 데이터, 원본인 학습용 레이블 데이터, 원본인 테스트 피처 데이터 그리고 K 폴드를 몇 개로 할지를 파라미터로 입력\n",
    "\n",
    "함수 내에서는 폴드의 개수만큼 반복 수행 → 폴드된 학습용 데이터로 학습한 뒤 예측 결과값을 기반으로 메타 모델을 위한 학습/테스트용 데이터 새롭게 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b5d8933f-4a8e-4aaf-87e3-3fd717f34b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test,  7)    \n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9b261476-2b7c-4c92-a46a-81e1e40521f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 학습 피처 데이터 Shape: (455, 30) 원본 테스트 피처 Shape: (114, 30)\n",
      "스태킹 학습 피처 데이터 Shape: (455, 4) 스태킹 테스트 피처 데이터 Shape: (114, 4)\n"
     ]
    }
   ],
   "source": [
    "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "print('원본 학습 피처 데이터 Shape:',X_train.shape, '원본 테스트 피처 Shape:',X_test.shape)\n",
    "print('스태킹 학습 피처 데이터 Shape:', Stack_final_X_train.shape,\n",
    "      '스태킹 테스트 피처 데이터 Shape:',Stack_final_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eed7fc24-1ec1-4bbc-8a34-b36567f0311a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9737\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(Stack_final_X_train, y_train)\n",
    "stack_final = lr_final.predict(Stack_final_X_test)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, stack_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51632625-8905-4d02-98ec-34883633c9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
