{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60eca587-0449-48fa-9fa1-2a74e04bca7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2688 - accuracy: 0.9233\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1073 - accuracy: 0.9686\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0704 - accuracy: 0.9792\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0508 - accuracy: 0.9851\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0378 - accuracy: 0.9886\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[5.9283838e-08 5.7110743e-09 3.2475418e-06 2.8610153e-05 2.7759460e-11\n",
      " 2.6299018e-08 6.6455049e-12 9.9996674e-01 4.0099074e-08 1.2271082e-06]\n",
      "7\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0656 - accuracy: 0.9803\n",
      "0.06556940823793411\n",
      "0.9803000092506409\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 6\n  y sizes: 5\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m#1 필수\u001b[39;00m\n\u001b[0;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(x,y)\n\u001b[0;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m30\u001b[39m]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1848\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1842\u001b[0m         label,\n\u001b[0;32m   1843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m   1844\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1845\u001b[0m         ),\n\u001b[0;32m   1846\u001b[0m     )\n\u001b[0;32m   1847\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1848\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 6\n  y sizes: 5\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()\n",
    "#모델 생성,숫자 변환, 학습\n",
    "model = keras.Sequential([layers.Dense(512,activation='relu'),\n",
    "\t\t(layers.Dense(10, activation='softmax'))])\n",
    "\t\t# 2층 레이어(두번째 층은 10개의 확률점수배열(그림이 각 숫자일 확률))\n",
    "model.compile(optimizer='rmsprop',loss='sparse_categorical_crossentropy', \n",
    "\t\tmetrics=['accuracy'])\n",
    "train_images = train_images.reshape((60000, 28*28)) # 28*28의 2차원 그림을 아닌 1차원(1줄숫자)으로 변환\n",
    "train_images = train_images.astype('float32')/255 #딥러닝 -> 정수가 아닌 0~1사이의 실수로 변환\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32')/255\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)#Epoch1/5 469/469\n",
    "\t#epoch는 학습반복횟수, batch_size는 cpu가 묶어서 처리하는 양(보통 32, 64, 128)\n",
    "\n",
    "# 예측\n",
    "test_digits = test_images[0:10]\n",
    "predictions = model.predict(test_digits)\n",
    "print(predictions[0])\n",
    "print(predictions[0].argmax()) #7(첫 번째 그림은 7일 확률이 가장 높음)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels) # 예측 + 평가\n",
    "print(test_loss) #0.06790909171104431\n",
    "print(test_acc) #0.9786999821662903\n",
    "\n",
    "#빈모델 생성 후 레이어 쌓는 방법\n",
    "x = np.array([1,2,3,4,5,6])\n",
    "y = np.array([5,8,11,14,17]) # y = 3*x + 2\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(units=10, input_dim=1)) #10은 임의, input_dim 필수\n",
    "model.add(keras.layers.Dense(units=1)) #1 필수\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mse'])\n",
    "model.fit(x,y, epochs=1000)\n",
    "model.evaluate(x,y)\n",
    "model.predict(np.array([10,20,30]))\n",
    "model.summary() #layer가 입력층 빼고 두 개나옴 \n",
    "#Layer (type)                Output Shape              Param \n",
    "#dense_19 (Dense)            (None, 10)                20        \n",
    "#dense_20 (Dense)            (None, 1)                 11(10+1)\n",
    "#Total params: 31(20+11)\n",
    "#출력층 None은 위에는 6\n",
    "\n",
    "#빈모델 생성 후 입력층 차원 지정을 먼저 하는 방법\n",
    "model.add(keras.layers.Input(shape=(1,))) #이부분 때문에 뒷줄 input_dim x\n",
    "model.add(keras.layers.Dense(units=18)) #앞줄은 입력층지정, 진짜 입력층\n",
    "\n",
    "#일부만 학습하고 일부로 테스트\n",
    "#활성화함수를 은닉층에 주지 않으면 예측이 거의 x축과 평행(학습 잘못시킴)\n",
    "#레이어수 ↑ -> 정확도 ↑\n",
    "x = np.arange(-1,1,0.01)\n",
    "a = np.random.permutation(x) \n",
    "train_x= a[:150]\n",
    "test_x = a[150:]\n",
    "#np.random.shuffle(x)\n",
    "#train_x=x[:150]\n",
    "#test_x=x[150:]로 해도 됨\n",
    "y = train_x**2+1\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape=(1,)))\n",
    "model.add(keras.layers.Dense(units=15, activation='relu')) \n",
    "model.add(keras.layers.Dense(units=10, activation='relu')) \n",
    "model.add(keras.layers.Dense(units=15, activation='relu')) \n",
    "model.add(keras.layers.Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mse', metrics='mse')\n",
    "model.fit(train_x,y, epochs=1000, verbose=False)\n",
    "plt.scatter(train_x,y)\n",
    "plt.scatter(test_x, model.predict(test_x))\n",
    "\n",
    "#x가 2개, y가 1개 -> 여기서부터는 시각화 불가(train_x가 2차원이라\n",
    "x = np.arange(-1,1,0.01)\n",
    "x = np.vstack([x,x*2]).T\n",
    "np.random.shuffle(x)\n",
    "train_x = x[:150]\n",
    "test_x = x[150:]\n",
    "y = train_x[:,0]+train_x[:,1] #y = y[:, np.newaxis] 안 해도 됨\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape=(2,)))\n",
    "model.add(keras.layers.Dense(units=15, activation='relu')) \n",
    "model.add(keras.layers.Dense(units=10, activation='relu')) \n",
    "model.add(keras.layers.Dense(units=15, activation='relu')) \n",
    "model.add(keras.layers.Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mse', metrics='mse')\n",
    "model.fit(train_x,y, epochs=1000, verbose=False)\n",
    "model.predict(np.array([[-1.3, -2.6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524e9e5-8cb0-4cb5-9842-c0193a9360ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
